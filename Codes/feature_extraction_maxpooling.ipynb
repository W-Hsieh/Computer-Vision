{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e291ed0a",
   "metadata": {},
   "source": [
    "# List of left and right images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f3a011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:58:53.071226Z",
     "start_time": "2023-10-20T01:58:53.054443Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Read training images\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "train_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "train_right_images_list = dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06bc695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:58:53.104527Z",
     "start_time": "2023-10-20T01:58:53.073751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read test images\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "test_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "test_right_images_list = dir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edb78a",
   "metadata": {},
   "source": [
    "# Define feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10881b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:58:55.808950Z",
     "start_time": "2023-10-20T01:58:53.106507Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "import secrets\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e811f30f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:58:55.824916Z",
     "start_time": "2023-10-20T01:58:55.811425Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_VGG(img_path):\n",
    "    # Load the VGG16 model pretrained on ImageNet data\n",
    "    model = VGG16(include_top=False, weights='imagenet', pooling='max')\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()\n",
    "\n",
    "def extract_features_ResNet(img_path):\n",
    "    # Load the ResNet50 model pretrained on ImageNet data\n",
    "    model = ResNet50(include_top=False, weights='imagenet', pooling='max')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()\n",
    "\n",
    "def extract_features_DenseNet(img_path):\n",
    "    # Load the DenseNet121 model pretrained on ImageNet data\n",
    "    model = DenseNet121(include_top=False, weights='imagenet', pooling='max')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1bfdc",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd4315",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f3eafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:18:36.498630Z",
     "start_time": "2023-10-20T01:58:55.824916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E4383E2280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E4383E20D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233530ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:37:57.336596Z",
     "start_time": "2023-10-20T02:18:36.502633Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(train_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\right\\\\{}'.format(train_right_images_list[i])\n",
    "    right_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fafbe4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:37:57.369361Z",
     "start_time": "2023-10-20T02:37:57.337712Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_train_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfd62f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:37:57.400331Z",
     "start_time": "2023-10-20T02:37:57.375739Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_train_right.npy', right_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52963c4e",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c97a596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:53:32.506689Z",
     "start_time": "2023-10-14T07:36:05.313740Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(test_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\left\\\\{}'.format(test_left_images_list[i])\n",
    "    left_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8782c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T08:11:16.467534Z",
     "start_time": "2023-10-14T07:53:32.516690Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(test_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\right\\\\{}'.format(test_right_images_list[i])\n",
    "    right_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f763e7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T08:11:16.483557Z",
     "start_time": "2023-10-14T08:11:16.468676Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_test_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58745d04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T08:11:16.499708Z",
     "start_time": "2023-10-14T08:11:16.486613Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_test_right.npy', right_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29e2d3",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e8522",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f401aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T09:19:59.963959Z",
     "start_time": "2023-10-14T08:11:16.502337Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 32s 0us/step\n",
      "94781440/94765736 [==============================] - 32s 0us/step\n"
     ]
    }
   ],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_ResNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b966a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T10:28:26.055968Z",
     "start_time": "2023-10-14T09:19:59.965970Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(train_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\right\\\\{}'.format(train_right_images_list[i])\n",
    "    right_features.append(extract_features_ResNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b70ca5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T10:28:26.086689Z",
     "start_time": "2023-10-14T10:28:26.057971Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('resnet_train_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dbe6e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T10:28:26.118374Z",
     "start_time": "2023-10-14T10:28:26.088691Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('resnet_train_right.npy', right_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99067f3",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5818ff0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T11:36:58.263065Z",
     "start_time": "2023-10-14T10:28:26.119889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(test_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\left\\\\{}'.format(test_left_images_list[i])\n",
    "    left_features.append(extract_features_ResNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "820b82d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T12:46:22.071679Z",
     "start_time": "2023-10-14T11:36:58.264950Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(test_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\right\\\\{}'.format(test_right_images_list[i])\n",
    "    right_features.append(extract_features_ResNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2df24d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T12:46:22.117497Z",
     "start_time": "2023-10-14T12:46:22.074568Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('resnet_test_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f0a45c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T12:46:22.149059Z",
     "start_time": "2023-10-14T12:46:22.120026Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('resnet_test_right.npy', right_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e9a3d",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bb15c",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bc775f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T16:16:29.916481Z",
     "start_time": "2023-10-14T14:08:16.758953Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_DenseNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64731573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T20:58:23.729085Z",
     "start_time": "2023-10-14T16:16:29.916481Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(train_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\right\\\\{}'.format(train_right_images_list[i])\n",
    "    right_features.append(extract_features_DenseNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38fbe23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T20:58:23.854471Z",
     "start_time": "2023-10-14T20:58:23.729731Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('densenet_train_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0de8f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T20:58:23.932802Z",
     "start_time": "2023-10-14T20:58:23.868737Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('densenet_train_right.npy', right_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64496409",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8b14bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T02:53:25.609262Z",
     "start_time": "2023-10-15T00:40:20.643483Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(test_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\left\\\\{}'.format(test_left_images_list[i])\n",
    "    left_features.append(extract_features_DenseNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "851e7e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T04:52:05.903795Z",
     "start_time": "2023-10-15T02:53:25.609773Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(test_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\right\\\\{}'.format(test_right_images_list[i])\n",
    "    right_features.append(extract_features_DenseNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a9988ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T04:52:05.935419Z",
     "start_time": "2023-10-15T04:52:05.903795Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('densenet_test_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a2f7ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T04:52:05.962196Z",
     "start_time": "2023-10-15T04:52:05.935419Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('densenet_test_right.npy', right_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc916e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
