{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74c0d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.327585Z",
     "start_time": "2023-10-19T18:26:13.237861Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37e3c2",
   "metadata": {},
   "source": [
    "# Read test_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24f5bbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.390450Z",
     "start_time": "2023-10-19T18:26:16.346535Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c10</th>\n",
       "      <th>c11</th>\n",
       "      <th>c12</th>\n",
       "      <th>c13</th>\n",
       "      <th>c14</th>\n",
       "      <th>c15</th>\n",
       "      <th>c16</th>\n",
       "      <th>c17</th>\n",
       "      <th>c18</th>\n",
       "      <th>c19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abm</td>\n",
       "      <td>kyr</td>\n",
       "      <td>qqo</td>\n",
       "      <td>xpv</td>\n",
       "      <td>tnd</td>\n",
       "      <td>xal</td>\n",
       "      <td>pvr</td>\n",
       "      <td>nsb</td>\n",
       "      <td>yzv</td>\n",
       "      <td>ahb</td>\n",
       "      <td>...</td>\n",
       "      <td>drb</td>\n",
       "      <td>vqu</td>\n",
       "      <td>vzr</td>\n",
       "      <td>kxe</td>\n",
       "      <td>mdq</td>\n",
       "      <td>oai</td>\n",
       "      <td>nmm</td>\n",
       "      <td>yzu</td>\n",
       "      <td>ihk</td>\n",
       "      <td>zwv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aci</td>\n",
       "      <td>jzn</td>\n",
       "      <td>hxw</td>\n",
       "      <td>iaj</td>\n",
       "      <td>edq</td>\n",
       "      <td>huu</td>\n",
       "      <td>huk</td>\n",
       "      <td>owo</td>\n",
       "      <td>ntd</td>\n",
       "      <td>uhk</td>\n",
       "      <td>...</td>\n",
       "      <td>mhg</td>\n",
       "      <td>exb</td>\n",
       "      <td>pny</td>\n",
       "      <td>kbo</td>\n",
       "      <td>tdb</td>\n",
       "      <td>sok</td>\n",
       "      <td>zsq</td>\n",
       "      <td>yfg</td>\n",
       "      <td>iqx</td>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acn</td>\n",
       "      <td>ksm</td>\n",
       "      <td>tyj</td>\n",
       "      <td>hhy</td>\n",
       "      <td>rph</td>\n",
       "      <td>axt</td>\n",
       "      <td>dby</td>\n",
       "      <td>xiv</td>\n",
       "      <td>aoc</td>\n",
       "      <td>oxb</td>\n",
       "      <td>...</td>\n",
       "      <td>vsu</td>\n",
       "      <td>wrx</td>\n",
       "      <td>zem</td>\n",
       "      <td>rkq</td>\n",
       "      <td>vjq</td>\n",
       "      <td>duq</td>\n",
       "      <td>ncp</td>\n",
       "      <td>mst</td>\n",
       "      <td>wzd</td>\n",
       "      <td>gup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aco</td>\n",
       "      <td>tft</td>\n",
       "      <td>bxn</td>\n",
       "      <td>vkl</td>\n",
       "      <td>mdq</td>\n",
       "      <td>iqb</td>\n",
       "      <td>uev</td>\n",
       "      <td>mjn</td>\n",
       "      <td>ccy</td>\n",
       "      <td>nje</td>\n",
       "      <td>...</td>\n",
       "      <td>flo</td>\n",
       "      <td>ltz</td>\n",
       "      <td>sjz</td>\n",
       "      <td>ind</td>\n",
       "      <td>fbw</td>\n",
       "      <td>ahy</td>\n",
       "      <td>vwe</td>\n",
       "      <td>cog</td>\n",
       "      <td>xcj</td>\n",
       "      <td>boz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acu</td>\n",
       "      <td>apn</td>\n",
       "      <td>zip</td>\n",
       "      <td>cxx</td>\n",
       "      <td>cwh</td>\n",
       "      <td>wbu</td>\n",
       "      <td>azy</td>\n",
       "      <td>qoe</td>\n",
       "      <td>wnd</td>\n",
       "      <td>xoo</td>\n",
       "      <td>...</td>\n",
       "      <td>zwq</td>\n",
       "      <td>rqi</td>\n",
       "      <td>rei</td>\n",
       "      <td>poj</td>\n",
       "      <td>gos</td>\n",
       "      <td>hif</td>\n",
       "      <td>ami</td>\n",
       "      <td>fhc</td>\n",
       "      <td>ift</td>\n",
       "      <td>xcj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  left   c0   c1   c2   c3   c4   c5   c6   c7   c8  ...  c10  c11  c12  c13  \\\n",
       "0  abm  kyr  qqo  xpv  tnd  xal  pvr  nsb  yzv  ahb  ...  drb  vqu  vzr  kxe   \n",
       "1  aci  jzn  hxw  iaj  edq  huu  huk  owo  ntd  uhk  ...  mhg  exb  pny  kbo   \n",
       "2  acn  ksm  tyj  hhy  rph  axt  dby  xiv  aoc  oxb  ...  vsu  wrx  zem  rkq   \n",
       "3  aco  tft  bxn  vkl  mdq  iqb  uev  mjn  ccy  nje  ...  flo  ltz  sjz  ind   \n",
       "4  acu  apn  zip  cxx  cwh  wbu  azy  qoe  wnd  xoo  ...  zwq  rqi  rei  poj   \n",
       "\n",
       "   c14  c15  c16  c17  c18  c19  \n",
       "0  mdq  oai  nmm  yzu  ihk  zwv  \n",
       "1  tdb  sok  zsq  yfg  iqx  jnj  \n",
       "2  vjq  duq  ncp  mst  wzd  gup  \n",
       "3  fbw  ahy  vwe  cog  xcj  boz  \n",
       "4  gos  hif  ami  fhc  ift  xcj  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_candidates = pd.read_csv('.\\COMP90086_2023_TLLdataset\\\\test_candidates.csv')\n",
    "test_candidates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e4015",
   "metadata": {},
   "source": [
    "# VGG without pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a991f",
   "metadata": {},
   "source": [
    "## Load feature extraction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787b8ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.343545Z",
     "start_time": "2023-10-19T18:26:16.328610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the feature extraction results\n",
    "\n",
    "# VGG without pooling\n",
    "left_test = np.load('vgg_test_left_all.npy')\n",
    "right_test = np.load('vgg_test_right_all.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3e71c",
   "metadata": {},
   "source": [
    "## Create dictionary of feature arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fdbaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.406427Z",
     "start_time": "2023-10-19T18:26:16.392446Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "test_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "test_right_images_list = dir_list\n",
    "\n",
    "left_array_dict = {}\n",
    "for i in range(len(test_left_images_list)):\n",
    "    left_array_dict[test_left_images_list[i][:3]] = left_test[i]\n",
    "    \n",
    "right_array_dict = {}\n",
    "for i in range(len(test_right_images_list)):\n",
    "    right_array_dict[test_right_images_list[i][:3]] = right_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c141a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:19.687611Z",
     "start_time": "2023-10-19T18:26:16.409072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create paires of extracted features\n",
    "pairs_for_test = []\n",
    "\n",
    "for j in range(len(test_candidates)):\n",
    "    for i in range(20):\n",
    "        pairs_for_test.append([left_array_dict.get(test_candidates.iloc[j][0]) , right_array_dict.get(test_candidates.iloc[j][i+1])])\n",
    "\n",
    "pairs_for_test = np.array(pairs_for_test)\n",
    "\n",
    "# Iterate over 40000 pairs\n",
    "overall_scores = []\n",
    "for i in range(40000):\n",
    "    scores = []\n",
    "    similarity_score = cosine_similarity(pairs_for_test[i][0], pairs_for_test[i][1])\n",
    "    scores.append(similarity_score)\n",
    "    overall_scores.append(scores)\n",
    "    \n",
    "overall_scores = np.array(overall_scores)\n",
    "\n",
    "# Reshape to the Kaggle format\n",
    "overall_scores = overall_scores.reshape(2000,20)\n",
    "\n",
    "overall_cos_similarity = pd.DataFrame(np.array(overall_scores))\n",
    "overall_cos_similarity.columns = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19']\n",
    "\n",
    "overall_cos_similarity['left'] = list(test_candidates['left'])\n",
    "\n",
    "cols = overall_cos_similarity.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "overall_cos_similarity = overall_cos_similarity[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e5b9a",
   "metadata": {},
   "source": [
    "## Output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea5ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the cosine similarity scores\n",
    "\n",
    "# VGG without pooling\n",
    "overall_cos_similarity.to_csv('vgg_all_test_cos_similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a96441",
   "metadata": {},
   "source": [
    "# VGG with max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f7c0e",
   "metadata": {},
   "source": [
    "## Load feature extraction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b452075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.343545Z",
     "start_time": "2023-10-19T18:26:16.328610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the feature extraction results\n",
    "\n",
    "# VGG max pooling\n",
    "left_test = np.load('vgg_test_left.npy')\n",
    "right_test = np.load('vgg_test_right.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df397838",
   "metadata": {},
   "source": [
    "## Create dictionary of feature arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e267c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.406427Z",
     "start_time": "2023-10-19T18:26:16.392446Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "test_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "test_right_images_list = dir_list\n",
    "\n",
    "left_array_dict = {}\n",
    "for i in range(len(test_left_images_list)):\n",
    "    left_array_dict[test_left_images_list[i][:3]] = left_test[i]\n",
    "    \n",
    "right_array_dict = {}\n",
    "for i in range(len(test_right_images_list)):\n",
    "    right_array_dict[test_right_images_list[i][:3]] = right_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb6414e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:19.687611Z",
     "start_time": "2023-10-19T18:26:16.409072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create paires of extracted features\n",
    "pairs_for_test = []\n",
    "\n",
    "for j in range(len(test_candidates)):\n",
    "    for i in range(20):\n",
    "        pairs_for_test.append([left_array_dict.get(test_candidates.iloc[j][0]) , right_array_dict.get(test_candidates.iloc[j][i+1])])\n",
    "\n",
    "pairs_for_test = np.array(pairs_for_test)\n",
    "\n",
    "# Iterate over 40000 pairs\n",
    "overall_scores = []\n",
    "for i in range(40000):\n",
    "    scores = []\n",
    "    similarity_score = cosine_similarity(pairs_for_test[i][0], pairs_for_test[i][1])\n",
    "    scores.append(similarity_score)\n",
    "    overall_scores.append(scores)\n",
    "    \n",
    "overall_scores = np.array(overall_scores)\n",
    "\n",
    "# Reshape to the Kaggle format\n",
    "overall_scores = overall_scores.reshape(2000,20)\n",
    "\n",
    "overall_cos_similarity = pd.DataFrame(np.array(overall_scores))\n",
    "overall_cos_similarity.columns = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19']\n",
    "\n",
    "overall_cos_similarity['left'] = list(test_candidates['left'])\n",
    "\n",
    "cols = overall_cos_similarity.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "overall_cos_similarity = overall_cos_similarity[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076ede1",
   "metadata": {},
   "source": [
    "## Output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c6daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the cosine similarity scores\n",
    "\n",
    "# VGG max pooling\n",
    "overall_cos_similarity.to_csv('vgg_test_cos_similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa1a83",
   "metadata": {},
   "source": [
    "# ResNet with max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790716d",
   "metadata": {},
   "source": [
    "## Load feature extraction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a6e3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.343545Z",
     "start_time": "2023-10-19T18:26:16.328610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the feature extraction results\n",
    "\n",
    "# ResNet max pooling \n",
    "left_test = np.load('resnet_test_left.npy')\n",
    "right_test = np.load('resnet_test_right.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194c076",
   "metadata": {},
   "source": [
    "## Create dictionary of feature arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82d4f44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.406427Z",
     "start_time": "2023-10-19T18:26:16.392446Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "test_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "test_right_images_list = dir_list\n",
    "\n",
    "left_array_dict = {}\n",
    "for i in range(len(test_left_images_list)):\n",
    "    left_array_dict[test_left_images_list[i][:3]] = left_test[i]\n",
    "    \n",
    "right_array_dict = {}\n",
    "for i in range(len(test_right_images_list)):\n",
    "    right_array_dict[test_right_images_list[i][:3]] = right_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16286f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:19.687611Z",
     "start_time": "2023-10-19T18:26:16.409072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create paires of extracted features\n",
    "pairs_for_test = []\n",
    "\n",
    "for j in range(len(test_candidates)):\n",
    "    for i in range(20):\n",
    "        pairs_for_test.append([left_array_dict.get(test_candidates.iloc[j][0]) , right_array_dict.get(test_candidates.iloc[j][i+1])])\n",
    "\n",
    "pairs_for_test = np.array(pairs_for_test)\n",
    "\n",
    "# Iterate over 40000 pairs\n",
    "overall_scores = []\n",
    "for i in range(40000):\n",
    "    scores = []\n",
    "    similarity_score = cosine_similarity(pairs_for_test[i][0], pairs_for_test[i][1])\n",
    "    scores.append(similarity_score)\n",
    "    overall_scores.append(scores)\n",
    "    \n",
    "overall_scores = np.array(overall_scores)\n",
    "\n",
    "# Reshape to the Kaggle format\n",
    "overall_scores = overall_scores.reshape(2000,20)\n",
    "\n",
    "overall_cos_similarity = pd.DataFrame(np.array(overall_scores))\n",
    "overall_cos_similarity.columns = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19']\n",
    "\n",
    "overall_cos_similarity['left'] = list(test_candidates['left'])\n",
    "\n",
    "cols = overall_cos_similarity.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "overall_cos_similarity = overall_cos_similarity[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55095244",
   "metadata": {},
   "source": [
    "## Output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56778919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the cosine similarity scores\n",
    "\n",
    "# ResNet max pooling\n",
    "overall_cos_similarity.to_csv('resnet_test_cos_similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f88ab",
   "metadata": {},
   "source": [
    "# DenseNet with max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c8dbc",
   "metadata": {},
   "source": [
    "## Load feature extraction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3b790c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.343545Z",
     "start_time": "2023-10-19T18:26:16.328610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the feature extraction results\n",
    "\n",
    "# DenseNet max pooling \n",
    "left_test = np.load('densenet_test_left.npy')\n",
    "right_test = np.load('densenet_test_right.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe687c",
   "metadata": {},
   "source": [
    "## Create dictionary of feature arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8993f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:16.406427Z",
     "start_time": "2023-10-19T18:26:16.392446Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "test_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "test_right_images_list = dir_list\n",
    "\n",
    "left_array_dict = {}\n",
    "for i in range(len(test_left_images_list)):\n",
    "    left_array_dict[test_left_images_list[i][:3]] = left_test[i]\n",
    "    \n",
    "right_array_dict = {}\n",
    "for i in range(len(test_right_images_list)):\n",
    "    right_array_dict[test_right_images_list[i][:3]] = right_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "382d60fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T18:26:19.687611Z",
     "start_time": "2023-10-19T18:26:16.409072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create paires of extracted features\n",
    "pairs_for_test = []\n",
    "\n",
    "for j in range(len(test_candidates)):\n",
    "    for i in range(20):\n",
    "        pairs_for_test.append([left_array_dict.get(test_candidates.iloc[j][0]) , right_array_dict.get(test_candidates.iloc[j][i+1])])\n",
    "\n",
    "pairs_for_test = np.array(pairs_for_test)\n",
    "\n",
    "# Iterate over 40000 pairs\n",
    "overall_scores = []\n",
    "for i in range(40000):\n",
    "    scores = []\n",
    "    similarity_score = cosine_similarity(pairs_for_test[i][0], pairs_for_test[i][1])\n",
    "    scores.append(similarity_score)\n",
    "    overall_scores.append(scores)\n",
    "    \n",
    "overall_scores = np.array(overall_scores)\n",
    "\n",
    "# Reshape to the Kaggle format\n",
    "overall_scores = overall_scores.reshape(2000,20)\n",
    "\n",
    "overall_cos_similarity = pd.DataFrame(np.array(overall_scores))\n",
    "overall_cos_similarity.columns = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19']\n",
    "\n",
    "overall_cos_similarity['left'] = list(test_candidates['left'])\n",
    "\n",
    "cols = overall_cos_similarity.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "overall_cos_similarity = overall_cos_similarity[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5424f",
   "metadata": {},
   "source": [
    "## Output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a1dbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the cosine similarity scores\n",
    "\n",
    "# DenseNet max pooling\n",
    "overall_cos_similarity.to_csv('densenet_test_cos_similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15a6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CV]",
   "language": "python",
   "name": "conda-env-CV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
