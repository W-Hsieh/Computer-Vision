{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4876d0d9",
   "metadata": {},
   "source": [
    "# List of left and right images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edac32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:59:15.750613Z",
     "start_time": "2023-10-20T01:59:15.730894Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Read training images\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "train_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "train_right_images_list = dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368b32c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:59:15.761244Z",
     "start_time": "2023-10-20T01:59:15.751829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read test images\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "test_left_images_list = dir_list\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\test\\\\right\"\n",
    "dir_list = os.listdir(path)\n",
    "test_right_images_list = dir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493986fc",
   "metadata": {},
   "source": [
    "# Define feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8d8f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:59:19.856695Z",
     "start_time": "2023-10-20T01:59:15.761244Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "import secrets\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5792a836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T01:59:19.876922Z",
     "start_time": "2023-10-20T01:59:19.866749Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_VGG(img_path):\n",
    "    # Load the VGG16 model pretrained on ImageNet data\n",
    "    model = VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c617b0",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb88f1",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9d5578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:19:10.396450Z",
     "start_time": "2023-10-20T01:59:19.884349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022E50894160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022E506EAB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac1ab14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:39:25.399044Z",
     "start_time": "2023-10-20T02:19:10.399496Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(train_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\right\\\\{}'.format(train_right_images_list[i])\n",
    "    right_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d127cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:39:25.926476Z",
     "start_time": "2023-10-20T02:39:25.400112Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_train_left_all.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c737664c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:39:26.178849Z",
     "start_time": "2023-10-20T02:39:25.926476Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_train_right_all.npy', right_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36afd0",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e0af850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:53:32.506689Z",
     "start_time": "2023-10-14T07:36:05.313740Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(test_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\left\\\\{}'.format(test_left_images_list[i])\n",
    "    left_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "270356e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T08:11:16.467534Z",
     "start_time": "2023-10-14T07:53:32.516690Z"
    }
   },
   "outputs": [],
   "source": [
    "right_features = []\n",
    "\n",
    "for i in range(len(test_right_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\test\\\\right\\\\{}'.format(test_right_images_list[i])\n",
    "    right_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e123c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T08:11:16.483557Z",
     "start_time": "2023-10-14T08:11:16.468676Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_test_left_all.npy', left_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a3937e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T08:11:16.499708Z",
     "start_time": "2023-10-14T08:11:16.486613Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('vgg_test_right_all.npy', right_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6926a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
