{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47b5727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:42:55.954055Z",
     "start_time": "2023-10-20T02:42:52.627701Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "import secrets\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834e40f",
   "metadata": {},
   "source": [
    "# Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cf36b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:42:55.973972Z",
     "start_time": "2023-10-20T02:42:55.954055Z"
    }
   },
   "outputs": [],
   "source": [
    "parent_dir = os.getcwd()\n",
    "directory = ['L1', 'L2', 'L1_augmented', 'L2_augmented']\n",
    "\n",
    "for i in directory:\n",
    "    path = os.path.join(parent_dir, i) \n",
    "    os.mkdir(path) \n",
    "    \n",
    "path = os.path.join(parent_dir, 'COMP90086_2023_TLLdataset', 'train', 'left_augmented')\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa3e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:16:49.589507Z",
     "start_time": "2023-10-15T17:16:49.583843Z"
    }
   },
   "source": [
    "# Implement data augmentation\n",
    "- Horizontal Flip\n",
    "- Contrast\n",
    "- Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2798c384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:43:14.602534Z",
     "start_time": "2023-10-20T02:42:55.973972Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "train_left_images_list = dir_list\n",
    "\n",
    "# https://www.geeksforgeeks.org/how-to-flip-an-image-horizontally-or-vertically-in-python/\n",
    "# https://www.tutorialspoint.com/how-to-change-the-contrast-and-brightness-of-an-image-using-opencv-in-python\n",
    "\n",
    "for i in train_left_images_list:\n",
    "    # open the original image\n",
    "    original_img = Image.open(\".\\COMP90086_2023_TLLdataset\\\\train\\\\left\\\\{}\".format(i))\n",
    "\n",
    "    horz_img = original_img.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "    horz_img.save(\".\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\{}_1.jpg\".format(i[:3]))\n",
    "    \n",
    "    # close all our files object\n",
    "    original_img.close()\n",
    "    horz_img.close()\n",
    "    \n",
    "    # read the input image\n",
    "    image_ = cv2.imread(\".\\COMP90086_2023_TLLdataset\\\\train\\\\left\\\\{}\".format(i))\n",
    "\n",
    "    # define the alpha and beta\n",
    "    alpha = 1.1 # Contrast control\n",
    "    # call convertScaleAbs function\n",
    "    adjusted = cv2.convertScaleAbs(image_, alpha=alpha)\n",
    "    cv2.imwrite(\".\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\{}_2.jpg\".format(i[:3]), adjusted)\n",
    "    \n",
    "    beta = -10 # Brightness control\n",
    "    # call convertScaleAbs function\n",
    "    adjusted2 = cv2.convertScaleAbs(image_, beta=beta)\n",
    "    cv2.imwrite(\".\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\{}_3.jpg\".format(i[:3]), adjusted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80691cf",
   "metadata": {},
   "source": [
    "# Define feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66fdf6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:43:14.617602Z",
     "start_time": "2023-10-20T02:43:14.605864Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_VGG(img_path):\n",
    "    # Load the VGG16 model pretrained on ImageNet data\n",
    "    model = VGG16(include_top=False, weights='imagenet', pooling='max')\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()\n",
    "\n",
    "def extract_features_ResNet(img_path):\n",
    "    # Load the ResNet50 model pretrained on ImageNet data\n",
    "    model = ResNet50(include_top=False, weights='imagenet', pooling='max')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()\n",
    "\n",
    "def extract_features_DenseNet(img_path):\n",
    "    # Load the DenseNet121 model pretrained on ImageNet data\n",
    "    model = DenseNet121(include_top=False, weights='imagenet', pooling='max')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # Preprocess input\n",
    "    array = preprocess_input(array)\n",
    "    # Extract features\n",
    "    features = model.predict(array)\n",
    "\n",
    "    # Flatten the features to convert it to 1D array\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b6eec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:43:14.632881Z",
     "start_time": "2023-10-20T02:43:14.620038Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\\"\n",
    "dir_list = os.listdir(path)\n",
    "train_left_images_list = dir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176a8bf",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5002cba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:35:10.531083Z",
     "start_time": "2023-10-20T02:43:14.635122Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C535B87670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C535B874C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_VGG(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3443b67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:35:10.561335Z",
     "start_time": "2023-10-20T03:35:10.531083Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('AUG_vgg_train_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71dfca",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea697d1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T21:30:47.264920Z",
     "start_time": "2023-10-15T18:09:25.720907Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_ResNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8090ef37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T21:30:47.337028Z",
     "start_time": "2023-10-15T21:30:47.264920Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('AUG_resnet_train_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f983e8",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "108c9adb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T03:12:47.347806Z",
     "start_time": "2023-10-15T21:30:47.339544Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_features = []\n",
    "\n",
    "for i in range(len(train_left_images_list)):\n",
    "    img_path = '.\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\\\\{}'.format(train_left_images_list[i])\n",
    "    left_features.append(extract_features_DenseNet(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54803397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T03:12:47.395343Z",
     "start_time": "2023-10-16T03:12:47.347806Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('AUG_densenet_train_left.npy', left_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90255b",
   "metadata": {},
   "source": [
    "# Create a new CSV file for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f713b6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:38:07.963978Z",
     "start_time": "2023-10-20T03:38:07.790488Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\".\\COMP90086_2023_TLLdataset\\\\train.csv\")\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\left_augmented\"\n",
    "dir_list = os.listdir(path)\n",
    "train_left_images_list = dir_list\n",
    "\n",
    "# Create two lists to store the corresponding filenames of left and right images \n",
    "left = []\n",
    "right = []\n",
    "for i in range(len(train_left_images_list)):\n",
    "    if train_left_images_list[i][:3] == train_data['left'][i//3]:\n",
    "        left.append(train_left_images_list[i][:5])\n",
    "        right.append(train_data['right'][i//3])\n",
    "        \n",
    "augmented = pd.DataFrame({'left': left, 'right': right})\n",
    "train_overall = pd.concat([train_data, augmented])\n",
    "# Save to CSV\n",
    "train_overall.to_csv('.\\COMP90086_2023_TLLdataset\\\\train_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad588f",
   "metadata": {},
   "source": [
    "# Copy the original left images to the \"left_augmented\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0494f449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:38:13.020784Z",
     "start_time": "2023-10-20T03:38:10.293479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy the original left images to the \"left_augmented\" folder\n",
    "\n",
    "path = \".\\COMP90086_2023_TLLdataset\\\\train\\\\left\"\n",
    "dir_list = os.listdir(path)\n",
    "train_left_images_list = dir_list\n",
    "\n",
    "for i in train_left_images_list:\n",
    "    src = os.path.join(parent_dir, 'COMP90086_2023_TLLdataset', 'train', 'left', i)\n",
    "    dst = os.path.join(parent_dir, 'COMP90086_2023_TLLdataset', 'train', 'left_augmented')\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff8b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
